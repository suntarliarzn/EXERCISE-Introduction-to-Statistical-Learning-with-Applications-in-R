best.subset.errors
mean.best.subset.errors=apply(best.subset.errors,2,mean)
which.min(mean.best.subset.errors)
best.subset.mse=mean.best.subset.errors[9] #mse=41.28
best.subset.mse
plot(mean.best.subset.errors, pch = 19, type = "b")
coef(best.subset,9)
best.subset.pred=predict(best.subset,Boston[test,], id=9)
#---------------------
# m=12
# best.subset.mse=42.46014
#   (Intercept)            zn         indus          chas           nox            rm           dis
#  17.497941702   0.044484580  -0.049548682  -0.650910395 -10.423803332   0.516804230  -0.986325634
#           rad           tax       ptratio         black         lstat          medv
#   0.579541936  -0.003483666  -0.247412156  -0.010275383   0.105147589  -0.206770151
#-----------------------
mse=c(best.subset.mse, ridge.mse,lasso.mse,pcr.test.mse)
barplot(mse,xlab="Models", ylab="test mse", names=c("best subset","ridge","lasso", "pcr"))
test.avg = mean(y.test)
best.subset.r=1-mean((best.subset.pred-y.test)^2)/mean((test.avg-y.test)^2)
ridge.r=1-mean((ridge.pred-y.test)^2)/mean((test.avg-y.test)^2)
lasso.r=1-mean((lasso.pred-y.test)^2)/mean((test.avg-y.test)^2)
pcr.r=1-mean((pcr.pred-y.test)^2)/mean((test.avg-y.test)^2)
barplot(c(best.subset.r, ridge.r, lasso.r, pcr.r), xlab = "Models", ylab="R2", names=c("best subset","ridge","lasso", "pcr") )
library(glmnet)
x=model.matrix(crim~.,Boston)[,-1]
y=Boston$crim
y.test=y[test]
ridge.cv=cv.glmnet(x,y, alpha =0)
plot(ridge.cv)
ridge.best.lambda=ridge.cv$lambda.min
ridge.mod=glmnet(x[train,],y[train], alpha=0)
plot(ridge.cv)
ridge.pred=predict(ridge.cv,newx=x[test,],s=ridge.best.lambda)
ridge.mse=mean((ridge.pred-y.test)^2)
ridge.mse #35.25636
coef(ridge.cv,s=ridge.best.lambda)[1:13,]
#------------------
# m=13
# ridge.mse=16.74
# (Intercept)           zn        indus         chas          nox           rm          age
# 13.611907278  0.036768943 -0.076738936 -0.277466933 -6.877273022  0.303179353  0.001688621
#         dis          rad          tax      ptratio        black        lstat
# -0.875991287  0.446777828  0.002425254 -0.177292650 -0.010992228  0.102658502
#------------------
library(glmnet)
x=model.matrix(crim~.,Boston)[,-1]
y=Boston$crim
y.test=y[test]
lasso.cv=cv.glmnet(x,y, alpha =1)
plot(lasso.cv)
lasso.best.lambda=lasso.cv$lambda.min
lasso.mod=glmnet(x[train,],y[train], alpha =1)
lasso.pred=predict(lasso.cv,x[test,],s=lasso.best.lambda)
lasso.mse=mean((lasso.pred-y.test)^2)
lasso.mse #34.908
plot(lasso.mod)
coef(lasso.cv)
#------------------
# m=11
# lasso.mse=35.39
#------------------
?Boston
library(leaps)
predict.regsubsets= function(object,newdata,id,...){
form = as.formula(object$call[[2]])
test.mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
test.mat[,names(coefi)]%*%coefi
}
k=10
best.subset.errors =matrix (NA,k,13, dimnames =list(NULL , paste(1:13) ))
folds=sample(1:k,nrow(Boston),replace=T)
for (i in 1:k){
best.subset=regsubsets(crim~., data=Boston[train,][folds!=i,], nvmax=13)
for (j in 1:13){
best.subset.pred=predict(best.subset,Boston[train,][folds==i,], id=j)
best.subset.errors[i,j]=mean((Boston[train,]$crim[folds==i]-best.subset.pred)^2)
}
}
set.seed(121)
library(ISLR)
library(MASS)
head(Boston)
summary(Boston)
dim(Boston)
train=sample(1:nrow(Boston),nrow(Boston)*0.8)
test=-train
boston.train=Boston[train,]
cri.test=Boston$crim[test]
library(leaps)
predict.regsubsets= function(object,newdata,id,...){
form = as.formula(object$call[[2]])
test.mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
test.mat[,names(coefi)]%*%coefi
}
k=10
best.subset.errors =matrix (NA,k,13, dimnames =list(NULL , paste(1:13) ))
folds=sample(1:k,nrow(Boston),replace=T)
for (i in 1:k){
best.subset=regsubsets(crim~., data=boston.train[folds!=i,], nvmax=13)
for (j in 1:13){
best.subset.pred=predict(best.subset,boston.train[folds==i,], id=j)
best.subset.errors[i,j]=mean((boston.train$crim[folds==i]-best.subset.pred)^2)
}
}
library(leaps)
predict.regsubsets= function(object,newdata,id,...){
form = as.formula(object$call[[2]])
test.mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
test.mat[,names(coefi)]%*%coefi
}
k=10
best.subset.errors =matrix (NA,k,13, dimnames =list(NULL , paste(1:13) ))
folds=sample(1:k,nrow(boston.train),replace=T)
for (i in 1:k){
best.subset=regsubsets(crim~., data=boston.train[folds!=i,], nvmax=13)
for (j in 1:13){
best.subset.pred=predict(best.subset,boston.train[folds==i,], id=j)
best.subset.errors[i,j]=mean((boston.train$crim[folds==i]-best.subset.pred)^2)
}
}
best.subset.errors
mean.best.subset.errors=apply(best.subset.errors,2,mean)
which.min(mean.best.subset.errors)
best.subset.mse=mean.best.subset.errors[9] #mse=41.28
best.subset.mse
plot(mean.best.subset.errors, pch = 19, type = "b")
coef(best.subset,9)
best.subset.pred=predict(best.subset,Boston[test,], id=9)
#---------------------
# m=12
# best.subset.mse=42.46014
#   (Intercept)            zn         indus          chas           nox            rm           dis
#  17.497941702   0.044484580  -0.049548682  -0.650910395 -10.423803332   0.516804230  -0.986325634
#           rad           tax       ptratio         black         lstat          medv
#   0.579541936  -0.003483666  -0.247412156  -0.010275383   0.105147589  -0.206770151
#-----------------------
library(leaps)
predict.regsubsets= function(object,newdata,id,...){
form = as.formula(object$call[[2]])
test.mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
test.mat[,names(coefi)]%*%coefi
}
k=10
best.subset.errors =matrix (NA,k,13, dimnames =list(NULL , paste(1:13) ))
folds=sample(1:k,nrow(boston.train),replace=T)
for (i in 1:k){
best.subset=regsubsets(crim~., data=boston.train[folds!=i,], nvmax=13)
for (j in 1:13){
best.subset.pred=predict(best.subset,boston.train[folds==i,], id=j)
best.subset.errors[i,j]=mean((boston.train$crim[folds==i]-best.subset.pred)^2)
}
}
best.subset.errors
mean.best.subset.errors=apply(best.subset.errors,2,mean)
which.min(mean.best.subset.errors)
best.subset.mse=mean.best.subset.errors[8] #mse=41.28
best.subset.mse
plot(mean.best.subset.errors, pch = 19, type = "b")
coef(best.subset,9)
best.subset.pred=predict(best.subset,Boston[test,], id=9)
#---------------------
# m=12
# best.subset.mse=42.46014
#   (Intercept)            zn         indus          chas           nox            rm           dis
#  17.497941702   0.044484580  -0.049548682  -0.650910395 -10.423803332   0.516804230  -0.986325634
#           rad           tax       ptratio         black         lstat          medv
#   0.579541936  -0.003483666  -0.247412156  -0.010275383   0.105147589  -0.206770151
#-----------------------
set.seed(1)
library(leaps)
predict.regsubsets= function(object,newdata,id,...){
form = as.formula(object$call[[2]])
test.mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
test.mat[,names(coefi)]%*%coefi
}
k=10
best.subset.errors =matrix (NA,k,13, dimnames =list(NULL , paste(1:13) ))
folds=sample(1:k,nrow(boston.train),replace=T)
for (i in 1:k){
best.subset=regsubsets(crim~., data=boston.train[folds!=i,], nvmax=13)
for (j in 1:13){
best.subset.pred=predict(best.subset,boston.train[folds==i,], id=j)
best.subset.errors[i,j]=mean((boston.train$crim[folds==i]-best.subset.pred)^2)
}
}
best.subset.errors
mean.best.subset.errors=apply(best.subset.errors,2,mean)
which.min(mean.best.subset.errors)
best.subset.mse=mean.best.subset.errors[8] #mse=41.28
best.subset.mse
plot(mean.best.subset.errors, pch = 19, type = "b")
coef(best.subset,9)
best.subset.pred=predict(best.subset,Boston[test,], id=9)
#---------------------
# m=12
# best.subset.mse=42.46014
#   (Intercept)            zn         indus          chas           nox            rm           dis
#  17.497941702   0.044484580  -0.049548682  -0.650910395 -10.423803332   0.516804230  -0.986325634
#           rad           tax       ptratio         black         lstat          medv
#   0.579541936  -0.003483666  -0.247412156  -0.010275383   0.105147589  -0.206770151
#-----------------------
set.seed(1)
library(leaps)
predict.regsubsets= function(object,newdata,id,...){
form = as.formula(object$call[[2]])
test.mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
test.mat[,names(coefi)]%*%coefi
}
k=10
best.subset.errors =matrix (NA,k,13, dimnames =list(NULL , paste(1:13) ))
folds=sample(1:k,nrow(boston.train),replace=T)
for (i in 1:k){
best.subset=regsubsets(crim~., data=boston.train[folds!=i,], nvmax=13)
for (j in 1:13){
best.subset.pred=predict(best.subset,boston.train[folds==i,], id=j)
best.subset.errors[i,j]=mean((boston.train$crim[folds==i]-best.subset.pred)^2)
}
}
best.subset.errors
mean.best.subset.errors=apply(best.subset.errors,2,mean)
which.min(mean.best.subset.errors)
best.subset.mse=mean.best.subset.errors[12] #mse=43.50
best.subset.mse
plot(mean.best.subset.errors, pch = 19, type = "b")
coef(best.subset,12)
best.subset.pred=predict(best.subset,Boston[test,], id=12)
#---------------------
# m=12
# best.subset.mse=42.46014
#   (Intercept)            zn         indus          chas           nox            rm           dis
#  17.497941702   0.044484580  -0.049548682  -0.650910395 -10.423803332   0.516804230  -0.986325634
#           rad           tax       ptratio         black         lstat          medv
#   0.579541936  -0.003483666  -0.247412156  -0.010275383   0.105147589  -0.206770151
#-----------------------
library(glmnet)
x=model.matrix(crim~.,Boston)[,-1]
y=Boston$crim
y.test=y[test]
ridge.cv=cv.glmnet(x[train,],y[train], alpha =0)
plot(ridge.cv)
ridge.best.lambda=ridge.cv$lambda.min
ridge.mod=glmnet(x[train,],y[train], alpha=0)
plot(ridge.cv)
ridge.pred=predict(ridge.mod,newx=x[test,],s=ridge.best.lambda)
ridge.mse=mean((ridge.pred-y.test)^2)
ridge.mse #35.25636
coef(ridge.cv,s=ridge.best.lambda)[1:13,]
#------------------
# m=13
# ridge.mse=16.74
# (Intercept)           zn        indus         chas          nox           rm          age
# 13.611907278  0.036768943 -0.076738936 -0.277466933 -6.877273022  0.303179353  0.001688621
#         dis          rad          tax      ptratio        black        lstat
# -0.875991287  0.446777828  0.002425254 -0.177292650 -0.010992228  0.102658502
#------------------
library(glmnet)
x=model.matrix(crim~.,Boston)[,-1]
y=Boston$crim
y.test=y[test]
ridge.cv=cv.glmnet(x[train,],y[train], alpha =0)
plot(ridge.cv)
ridge.best.lambda=ridge.cv$lambda.min
ridge.mod=glmnet(x[train,],y[train], alpha=0)
plot(ridge.cv)
ridge.pred=predict(ridge.mod,newx=x[test,],s=ridge.best.lambda)
ridge.mse=mean((ridge.pred-y.test)^2)
ridge.mse #35.784
coef(ridge.cv)[1:13,]
#------------------
# m=13
# ridge.mse=16.74
# (Intercept)           zn        indus         chas          nox           rm          age
# 13.611907278  0.036768943 -0.076738936 -0.277466933 -6.877273022  0.303179353  0.001688621
#         dis          rad          tax      ptratio        black        lstat
# -0.875991287  0.446777828  0.002425254 -0.177292650 -0.010992228  0.102658502
#------------------
library(glmnet)
x=model.matrix(crim~.,Boston)[,-1]
y=Boston$crim
y.test=y[test]
lasso.cv=cv.glmnet(x[train,],y[train], alpha =1)
plot(lasso.cv)
lasso.best.lambda=lasso.cv$lambda.min
lasso.mod=glmnet(x[train,],y[train], alpha =1)
lasso.pred=predict(lasso.cv,x[test,],s=lasso.best.lambda)
lasso.mse=mean((lasso.pred-y.test)^2)
lasso.mse #34.908
plot(lasso.mod)
coef(lasso.cv)
#------------------
# m=11
# lasso.mse=35.39
#------------------
library(glmnet)
x=model.matrix(crim~.,Boston)[,-1]
y=Boston$crim
y.test=y[test]
lasso.cv=cv.glmnet(x[train,],y[train], alpha =1)
plot(lasso.cv)
lasso.best.lambda=lasso.cv$lambda.min
lasso.mod=glmnet(x[train,],y[train], alpha =1)
lasso.pred=predict(lasso.cv,x[test,],s=lasso.best.lambda)
lasso.mse=mean((lasso.pred-y.test)^2)
lasso.mse #35.44
plot(lasso.mod)
coef(lasso.cv)
#------------------
# m=11
# lasso.mse=35.39
#------------------
library(glmnet)
x=model.matrix(crim~.,Boston)[,-1]
y=Boston$crim
y.test=y[test]
lasso.cv=cv.glmnet(x[train,],y[train], alpha =1)
plot(lasso.cv)
lasso.best.lambda=lasso.cv$lambda.min
lasso.mod=glmnet(x[train,],y[train], alpha =1)
lasso.pred=predict(lasso.cv,x[test,],s=lasso.best.lambda)
lasso.mse=mean((lasso.pred-y.test)^2)
lasso.mse #35.44
plot(lasso.mod)
coef(lasso.mod)
#------------------
# m=11
# lasso.mse=35.39
#------------------
library(glmnet)
x=model.matrix(crim~.,Boston)[,-1]
y=Boston$crim
y.test=y[test]
lasso.cv=cv.glmnet(x[train,],y[train], alpha =1)
plot(lasso.cv)
lasso.best.lambda=lasso.cv$lambda.min
lasso.mod=glmnet(x[train,],y[train], alpha =1)
lasso.pred=predict(lasso.cv,x[test,],s=lasso.best.lambda)
lasso.mse=mean((lasso.pred-y.test)^2)
lasso.mse #35.44
plot(lasso.mod)
coef(lasso.cv)
#------------------
# m=11
# lasso.mse=35.39
#------------------
library(pls)
pcr.fit=pcr(crim~., data=Boston[train,], scale=TRUE, validation="CV")
summary(pcr.fit)
validationplot(pcr.fit)
validationplot(pcr.fit,val.type="MSEP")
pcr.pred=predict(pcr.fit,Boston[test,],ncomp=8)
pcr.test.mse=mean((pcr.pred-y.test)^2)
pcr.test.mse #37.89
coef(pcr.fit, ncomp=8)
#------------------
# n=8
# pcr.test.mse=17.22
#------------------
mse=c(best.subset.mse, ridge.mse,lasso.mse,pcr.test.mse)
barplot(mse,xlab="Models", ylab="test mse", names=c("best subset","ridge","lasso", "pcr"))
test.avg = mean(y.test)
best.subset.r=1-mean((best.subset.pred-y.test)^2)/mean((test.avg-y.test)^2)
ridge.r=1-mean((ridge.pred-y.test)^2)/mean((test.avg-y.test)^2)
lasso.r=1-mean((lasso.pred-y.test)^2)/mean((test.avg-y.test)^2)
pcr.r=1-mean((pcr.pred-y.test)^2)/mean((test.avg-y.test)^2)
barplot(c(best.subset.r, ridge.r, lasso.r, pcr.r), xlab = "Models", ylab="R2", names=c("best subset","ridge","lasso", "pcr") )
setwd("E:/little-trowel/02_TC/04 Tools/4.2 R/07.moving beyond linear model")
knitr::opts_chunk$set(echo = TRUE)
library(splines)
fit=lm(wage~bs(age,knots = c(25,40,60)), data=Wage) #basic function
library(ISLR)
library(stats)
attach(Wage)
agelims=range(age)
age.grid=seq(from=agelims [1], to=agelims [2])
table(cut(age,breaks = c(17,34,49,65,81)))
library(splines)
fit=lm(wage~bs(age,knots = c(25,40,60)), data=Wage) #basic function
pred=predict(fit, newdata=list(age=age.grid), se=T)
plot(age,wage,col="gray")
lines(age.grid, pred$fit, lwd=2)
lines(age.grid, pred$fit+2*pred$se, lty=3)
lines(age.grid, pred$fit-2*pred$se, ;ty=3)
library(splines)
fit=lm(wage~bs(age,knots = c(25,40,60)), data=Wage) #basic function
pred=predict(fit, newdata=list(age=age.grid), se=T)
plot(age,wage,col="gray")
lines(age.grid, pred$fit, lwd=2)
lines(age.grid, pred$fit+2*pred$se, lty=3)
lines(age.grid, pred$fit-2*pred$se, lty=3)
library(splines)
fit=lm(wage~bs(age,knots = c(25,40,60)), data=Wage) #basic function
pred=predict(fit, newdata=list(age=age.grid), se=T)
plot(age,wage,col="gray")
lines(age.grid, pred$fit, lwd=2)
lines(age.grid, pred$fit+2*pred$se, lty=3, col="red")
lines(age.grid, pred$fit-2*pred$se, lty=3, col="red")
library(splines)
fit=lm(wage~bs(age,knots = c(25,40,60)), data=Wage) #basic function
pred=predict(fit, newdata=list(age=age.grid), se=T)
plot(age,wage,col="gray" ,ylim = c(0,250))
lines(age.grid, pred$fit, lwd=2)
lines(age.grid, pred$fit+2*pred$se, lty=3, col="red")
lines(age.grid, pred$fit-2*pred$se, lty=3, col="red")
dim(bs(age, knots=c(25,40,60)))
dim(Wage)
dim(bs(age, knots=c(25,40,60)))
dim(Wage)
dim(bs(age, knots=c(25,40,60)))
dim(Wage)
dim(bs(age, knots=c(25,40,60)))
dim(bs(age, df=6))
dim(Wage)
dim(bs(age, knots=c(25,40,60)))
dim(bs(age, df=4))
dim(Wage)
dim(bs(age, knots=c(25,40,60)))
dim(bs(age, df=4))
attr(dim(bs(age, df=4)))
dim(Wage)
dim(bs(age, knots=c(25,40,60)))
dim(bs(age, df=4))
attr(dim(bs(age, df=4)), "knots")
dim(Wage)
dim(bs(age, knots=c(25,40,60)))
dim(bs(age, df=4))
attr(dim(bs(age, df=7)), "knots")
dim(Wage)
dim(bs(age, knots=c(25,40,60)))
dim(bs(age, df=4))
attr(dim(bs(age, df=6)), "knots")
dim(Wage)
dim(bs(age, knots=c(25,40,60)))
dim(bs(age, df=4))
attr(bs(age, df=6))
dim(Wage)
dim(bs(age, knots=c(25,40,60)))
dim(bs(age, df=4))
attr(bs(age, df=6), "knots")
dim(Wage)
dim(bs(age, knots=c(25,40,60)))
dim(bs(age, df=4))
attr(bs(age, df=7), "knots")
dim(Wage)
dim(bs(age, knots=c(25,40,60)))
dim(bs(age, df=4))
attr(bs(age, df=4), "knots")
dim(Wage)
dim(bs(age, knots=c(25,40,60)))
dim(bs(age, df=4))
attr(bs(age, df=8), "knots")
library(splines)
fit=lm(wage~bs(age,knots = c(25,40,60)), data=Wage) #basic function
pred=predict(fit, newdata=list(age=age.grid), se=T)
plot(age,wage,col="gray" ,ylim = c(0,250))
lines(age.grid, pred$fit, lwd=2)
lines(age.grid, pred$fit+2*pred$se, lty=3, col="red")
lines(age.grid, pred$fit-2*pred$se, lty=3, col="red")
fit2=lm(wage~ns(age,df=4), data=Wage)
pred2=predict(fit2, newdata=list(age=age.grid), se=T)
lines(age.grid, pred2$fit, col="orange", lwd=2)
library(splines)
fit=lm(wage~bs(age,knots = c(25,40,60)), data=Wage) #basic function
pred=predict(fit, newdata=list(age=age.grid), se=T)
plot(age,wage,col="gray" ,ylim = c(0,250))
lines(age.grid, pred$fit, lwd=2)
lines(age.grid, pred$fit+2*pred$se, lty=3, col="red")
lines(age.grid, pred$fit-2*pred$se, lty=3, col="red")
fit2=lm(wage~ns(age,df=4), data=Wage)
pred2=predict(fit2, newdata=list(age=age.grid), se=T)
plot(age,wage,col="gray" ,ylim = c(0,250))
lines(age.grid, pred2$fit, col="orange", lwd=2)
library(splines)
fit=lm(wage~bs(age,knots = c(25,40,60)), data=Wage) #basic function
pred=predict(fit, newdata=list(age=age.grid), se=T)
plot(age,wage,col="gray")
lines(age.grid, pred$fit, lwd=2)
lines(age.grid, pred$fit+2*pred$se, lty=3, col="red")
lines(age.grid, pred$fit-2*pred$se, lty=3, col="red")
lines(age.grid, pred2$fit, col="orange", lwd=2)
fit2=lm(wage~ns(age,df=4), data=Wage)
pred2=predict(fit2, newdata=list(age=age.grid), se=T)
plot(age,wage,col="gray" ,ylim = c(0,200))
lines(age.grid, pred2$fit, col="orange", lwd=2)
lines(age.grid, pred$fit+2*pred$se, lty=3, col="red")
lines(age.grid, pred$fit-2*pred$se, lty=3, col="red")
fit2=lm(wage~ns(age,df=4), data=Wage)
pred2=predict(fit2, newdata=list(age=age.grid), se=T)
plot(age,wage,col="gray" ,ylim = c(0,200))
lines(age.grid, pred2$fit, col="orange", lwd=2)
lines(age.grid, pred$fit, lwd=2)
fit2=lm(wage~ns(age,df=4), data=Wage)
pred2=predict(fit2, newdata=list(age=age.grid), se=T)
plot(age,wage,col="gray" ,ylim = c(0,100))
lines(age.grid, pred2$fit, col="orange", lwd=2)
lines(age.grid, pred$fit, lwd=2)
fit2=lm(wage~ns(age,df=4), data=Wage)
pred2=predict(fit2, newdata=list(age=age.grid), se=T)
plot(age,wage,col="gray" ,ylim = c(0,200))
lines(age.grid, pred2$fit, col="orange", lwd=2)
lines(age.grid, pred$fit, lwd=2)
fit2=lm(wage~ns(age,df=4), data=Wage)
pred2=predict(fit2, newdata=list(age=age.grid), se=T)
plot(age,wage,col="gray" ,ylim = c(0,150))
lines(age.grid, pred2$fit, col="orange", lwd=2)
lines(age.grid, pred$fit, lwd=2)
