10.10.7 Default dataset
================

# 1.data preparation

``` r
library(keras)
library(ISLR2)
library(tensorflow)
head(Default)
```

    ##   default student   balance    income
    ## 1      No      No  729.5265 44361.625
    ## 2      No     Yes  817.1804 12106.135
    ## 3      No      No 1073.5492 31767.139
    ## 4      No      No  529.2506 35704.494
    ## 5      No      No  785.6559 38463.496
    ## 6      No     Yes  919.5885  7491.559

``` r
str(Default)
```

    ## 'data.frame':    10000 obs. of  4 variables:
    ##  $ default: Factor w/ 2 levels "No","Yes": 1 1 1 1 1 1 1 1 1 1 ...
    ##  $ student: Factor w/ 2 levels "No","Yes": 1 2 1 1 1 2 1 2 1 1 ...
    ##  $ balance: num  730 817 1074 529 786 ...
    ##  $ income : num  44362 12106 31767 35704 38463 ...

``` r
summary(Default)
```

    ##  default    student       balance           income     
    ##  No :9667   No :7056   Min.   :   0.0   Min.   :  772  
    ##  Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  
    ##                        Median : 823.6   Median :34553  
    ##                        Mean   : 835.4   Mean   :33517  
    ##                        3rd Qu.:1166.3   3rd Qu.:43808  
    ##                        Max.   :2654.3   Max.   :73554

# 2.training data

``` r
attach(Default)
dim(Default)
```

    ## [1] 10000     4

``` r
train=sample(nrow(Default),8000)
x=Default[,-1]
x.train=x[train,]
y.train=default[train]
y.test=default[-train]
```

# 3.lm

``` r
library(glmnet)
```

    ## 载入需要的程辑包：Matrix

    ## Warning: 程辑包'Matrix'是用R版本4.1.3 来建造的

    ## Loaded glmnet 4.1-3

``` r
lm.fit <- glm(default~.,data=Default,subset=train,family="binomial")
lm.pred <- predict(lm.fit, x[-train,],type="response")
lm.prob <- ifelse(lm.pred>0.5, "Yes","No")
table(lm.prob,y.test)
```

    ##        y.test
    ## lm.prob   No  Yes
    ##     No  1919   46
    ##     Yes    6   29

``` r
# (58+9)/(1904+9+58+29)=0.0335
```

# 4. neural network

``` r
# one-hot encode
y_train <- to_categorical(as.numeric(y.train))[,-1]
```

    ## Loaded Tensorflow version 2.8.0

``` r
y_test <- to_categorical(as.numeric(y.test))[,-1]
x <- cbind(student=as.numeric(x$student),x[,-1])
x <- as.matrix(x)
x_train <- x[train,]
x_test <- x[-train,]

model <- keras_model_sequential()
model %>% layer_dense(units=10, activation="relu", input_shape=c(3)) %>% layer_dropout(rate=0.4) %>%  layer_dense(units=2, activation = "softmax")
summary(model)
```

    ## Model: "sequential"
    ## ________________________________________________________________________________
    ##  Layer (type)                       Output Shape                    Param #     
    ## ================================================================================
    ##  dense_1 (Dense)                    (None, 10)                      40          
    ##                                                                                 
    ##  dropout (Dropout)                  (None, 10)                      0           
    ##                                                                                 
    ##  dense (Dense)                      (None, 2)                       22          
    ##                                                                                 
    ## ================================================================================
    ## Total params: 62
    ## Trainable params: 62
    ## Non-trainable params: 0
    ## ________________________________________________________________________________

``` r
model %>% compile(loss="binary_crossentropy", optimizer="rmsprop", metrics=c("accuracy"))
model %>% fit(x_train,y_train, epochs=10, batch_size=8, validation_data=list(x_test, y_test))
```
