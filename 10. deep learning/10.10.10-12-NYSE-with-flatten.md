10.10.10-12 NYSE with flatten
================

# 1.data preparation

``` r
library(ISLR2)
library(keras)
library(tensorflow)
x.data <- data.matrix(
  NYSE[,c("DJ_return","log_volume","log_volatility")]
)
y <- NYSE[,"train"]
x <- scale(x.data)
```

# 2.data processing

``` r
# 构造一个用前五天成交数据来预测当天成交量的数据集
lagm <- function(x,k=1){
  n <- nrow(x)
  pad <- matrix(NA, k,ncol(x))
  rbind(pad, x[1:(n-k),])
  }
arframe <- data.frame(log_volume = x[, "log_volume"], L1 = lagm(x , 1), L2 = lagm(x, 2), L3 = lagm(x , 3), L4 = lagm(x , 4), L5 = lagm(x , 5))
arframe <- arframe[-(1:5),]
y <- y[-(1:5)]
# install.packages("stringr") 正则表达式提取出月份加入数据中
library(stringr)
```

    ## Warning: 程辑包'stringr'是用R版本4.1.3 来建造的

``` r
date <- NYSE$date
date_str <- str_extract_all(date,"\\d+")
mon=integer()
for (i in c(1:6051)){
  mon_str=date_str[[i]][2]
  mon[i]=as.numeric(mon_str)
}
mon <- as.factor(mon)
df <- data.frame(mon=mon[-(1:5)],day=NYSE[-(1:5),"day_of_week"], arframe)
```

# 3.lm with MONTH

``` r
# install.packages("stringr") 正则表达式提取出月份加入数据中
library(stringr)
date <- NYSE$date
date_str <- str_extract_all(date,"\\d+")
mon=integer()
for (i in c(1:6051)){
  mon_str=date_str[[i]][2]
  mon[i]=as.numeric(mon_str)
}
mon <- as.factor(mon)
df <- data.frame(mon=mon[-(1:5)],day=NYSE[-(1:5),"day_of_week"], arframe)

lm.fit <- lm(log_volume~.,data=df[y,])
lm.pred <- predict(lm.fit, df[!y,])

v <- var(df[!y,"log_volume"])
1-mean((lm.pred-df[!y,"log_volume"])^2)/v
```

    ## [1] 0.4629872

``` r
# R^2=0.4599 加入month变为 R^2=0.4629
```

# 4. flatten linear AR model

``` r
n <- nrow(arframe)
xrnn <- data.matrix(arframe[,-1])
xrnn <- array(xrnn,c(n,3,5))
xrnn <- xrnn[,,5:1]
# 转置矩阵 将自变量作为分组依据
xrnn <- aperm(xrnn,c(1,3,2))

model <- keras_model_sequential()
```

    ## Loaded Tensorflow version 2.8.0

``` r
model %>% layer_flatten(input_shape=c(5,3)) %>%layer_dense(units=1)
model %>% compile(optimizer=optimizer_rmsprop(), loss="mse")
model %>% fit(xrnn[y,, ], arframe[y, "log_volume"], batch_size = 64, epochs = 50, validation_data = list(xrnn[!y,, ], arframe[!y , "log_volume"])
)
r.pred <- predict(model,xrnn[!y,,])
1-mean((r.pred-arframe[!y,"log_volume"])^2)/v
```

    ## [1] 0.4064885

``` r
# R^2=0.412
```

# 5. flatten nonlinear AR model

``` r
model <- keras_model_sequential()
model %>% layer_flatten(input_shape=c(5,3)) %>% 
  layer_dense(units = 12, activation="relu") %>% 
  layer_dense(units=1)
model %>% compile(optimizer=optimizer_rmsprop(), loss="mse")
model %>% fit( xrnn[y,, ], arframe[y, "log_volume"], batch_size = 64, epochs = 50, validation_data = list(xrnn[!y,, ], arframe[!y , "log_volume"])
)
r.pred <- predict(model,xrnn[!y,,])
1-mean((r.pred-arframe[!y,"log_volume"])^2)/v
```

    ## [1] 0.417475

``` r
# R^2=0.4065559
```

# 6. RNN with day_of_week

``` r
arfame1=arframe[,-1]
week <- as.factor(NYSE[-(1:5),"day_of_week"])
num.week <- as.numeric(week)
num.month <- as.numeric(mon[-(1:5)])
df1 <- data.frame(mon=num.month,day=num.week, arfame1[,1:3])
df2 <- data.frame(mon=num.month,day=num.week, arfame1[,4:6])
df3 <- data.frame(mon=num.month,day=num.week, arfame1[,7:9])
df4 <- data.frame(mon=num.month,day=num.week, arfame1[,10:12])
df5 <- data.frame(mon=num.month,day=num.week, arfame1[,13:15])
rnn.d <- data.frame(df1,df2,df3,df4,df5)
n <- nrow(rnn.d)
xrnn <- data.matrix(rnn.d)
xrnn <- array(xrnn,c(n,5,5))
xrnn <- xrnn[,,5:1]
# 转置矩阵 将自变量作为分组依据
xrnn <- aperm(xrnn,c(1,3,2))


model <- keras_model_sequential()
model %>% layer_simple_rnn(units=12,input_shape=list(5,5), dropout=0.1, recurrent_dropout = 0.1) %>% layer_dense(units=1)
model %>% compile(optimizer=optimizer_rmsprop(), loss="mse")
model %>% fit( xrnn[y,, ], arframe[y, "log_volume"], batch_size = 64, epochs = 100, validation_data = list(xrnn[!y,, ], arframe[!y , "log_volume"])
)
r.pred <- predict(model,xrnn[!y,,])
1-mean((r.pred-arframe[!y,"log_volume"])^2)/v
```

    ## [1] 0.4332288

``` r
# R^2=0.4269
```
