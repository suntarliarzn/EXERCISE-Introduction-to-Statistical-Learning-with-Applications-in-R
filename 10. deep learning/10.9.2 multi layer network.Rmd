---
title: "10.9.2 multi layer network"
output: html_document
---

# 1. Data preparation
```{R}
library(keras)
mnist <- dataset_mnist()
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y
```

# 2. Data processing
```{R}
x_train_mat <- array_reshape(x_train, c(nrow(x_train), 784))
x_test_mat <- array_reshape(x_test,c(nrow(x_test),784))
y_train_cat <-to_categorical(y_train)
y_test_cat <- to_categorical(y_test)
x_train_mat <- x_train_mat/255
x_test_mat <- x_test_mat/255
```

# 3. neural network
```{R}
model <- keras_model_sequential()
model %>% layer_dense(units=256, activation="relu", input_shape=c(784)) %>% layer_dropout(rate=0.4) %>% layer_dense(units=128, activation="relu") %>% layer_dropout(rate=0.3) %>% layer_dense(units=10, activation="softmax")
summary(model)
model %>% compile(loss="categorical_crossentropy", optimizer=optimizer_rmsprop(), metrics=c("accuracy"))
model %>% fit(x_train_mat,y_train_cat, epochs=10, batch_size=32, validation_split=0.2)
y_predict <- model %>% predict(x_test_mat) %>% k_argmax()
mean(as.numeric(y_predict)==as.numeric(y_test))
```

# 4.logistical regression
```{R}
modellr <- keras_model_sequential()
modellr %>% layer_dense(units=10, activation="softmax", input_shape=c(784))
summary(model)
modellr %>% compile(loss="categorical_crossentropy", optimizer=optimizer_rmsprop(), metrics=c("accuracy"))
modellr %>% fit(x_train_mat,y_train_cat, epochs=10, batch_size=32, validation_split=0.2)
y_predict <- modellr %>% predict(x_test_mat) %>% k_argmax()
mean(as.numeric(y_predict)==as.numeric(y_test))
```
